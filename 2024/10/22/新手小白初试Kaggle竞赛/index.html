<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"betty11618.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="https:&#x2F;&#x2F;www.kaggle.com&#x2F;competitions&#x2F;titanic  挑战泰坦尼克号沉没是历史上最臭名昭著的海难之一。 1912 年 4 月 15 日，在处女航中，被广泛认为“永不沉没”的皇家邮轮泰坦尼克号与冰山相撞后沉没。不幸的是，救生艇数量不足以容纳船上所有人，导致 2224 名乘客和船员中有 1502 人丧生。 尽管生存有一定的运气因素，但似乎有些人比其他人群更有可能生存">
<meta property="og:type" content="article">
<meta property="og:title" content="新手小白初试Kaggle竞赛">
<meta property="og:url" content="https://betty11618.github.io/2024/10/22/%E6%96%B0%E6%89%8B%E5%B0%8F%E7%99%BD%E5%88%9D%E8%AF%95Kaggle%E7%AB%9E%E8%B5%9B/index.html">
<meta property="og:site_name" content="recording...">
<meta property="og:description" content="https:&#x2F;&#x2F;www.kaggle.com&#x2F;competitions&#x2F;titanic  挑战泰坦尼克号沉没是历史上最臭名昭著的海难之一。 1912 年 4 月 15 日，在处女航中，被广泛认为“永不沉没”的皇家邮轮泰坦尼克号与冰山相撞后沉没。不幸的是，救生艇数量不足以容纳船上所有人，导致 2224 名乘客和船员中有 1502 人丧生。 尽管生存有一定的运气因素，但似乎有些人比其他人群更有可能生存">
<meta property="og:locale">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025557.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025204.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025970.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025971.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025972.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025973.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025974.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025975.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025976.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025977.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025978.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025979.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025980.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025981.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025982.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025983.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025984.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025985.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025986.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025987.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025988.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025989.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025990.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025991.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025992.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025993.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025994.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025995.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025996.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025997.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025998.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025999.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025000.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025001.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025002.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025003.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025004.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025005.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025006.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025007.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025008.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025009.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025010.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025011.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025012.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025013.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025014.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025015.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025016.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025017.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025018.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025019.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025020.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025021.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025022.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025023.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025024.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025025.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025026.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025027.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025028.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025029.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025030.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025031.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025032.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025033.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025034.png">
<meta property="og:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025035.png">
<meta property="article:published_time" content="2024-10-22T12:22:22.000Z">
<meta property="article:modified_time" content="2024-10-22T12:27:39.796Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/betty11618/images/img/202410222025557.png">

<link rel="canonical" href="https://betty11618.github.io/2024/10/22/%E6%96%B0%E6%89%8B%E5%B0%8F%E7%99%BD%E5%88%9D%E8%AF%95Kaggle%E7%AB%9E%E8%B5%9B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'default'
  };
</script>

  <title>新手小白初试Kaggle竞赛 | recording...</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">recording...</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="default">
    <link itemprop="mainEntityOfPage" href="https://betty11618.github.io/2024/10/22/%E6%96%B0%E6%89%8B%E5%B0%8F%E7%99%BD%E5%88%9D%E8%AF%95Kaggle%E7%AB%9E%E8%B5%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="recording...">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          新手小白初试Kaggle竞赛
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2024-10-22 20:22:22 / Modified: 20:27:39" itemprop="dateCreated datePublished" datetime="2024-10-22T20:22:22+08:00">2024-10-22</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/titanic">https://www.kaggle.com/competitions/titanic</a></p>
<blockquote>
<h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>泰坦尼克号沉没是历史上最臭名昭著的海难之一。</p>
<p>1912 年 4 月 15 日，在处女航中，被广泛认为“永不沉没”的皇家邮轮泰坦尼克号与冰山相撞后沉没。不幸的是，救生艇数量不足以容纳船上所有人，导致 2224 名乘客和船员中有 1502 人丧生。</p>
<p>尽管生存有一定的运气因素，但似乎有些人比其他人群更有可能生存下来。</p>
<p>在这个挑战中，我们要求您使用乘客数据（即姓名、年龄、性别、社会经济阶层等）建立一个预测模型，回答这个问题：“什么样的人更有可能生存？”</p>
</blockquote>
<h1 id="1-明确数据集中的变量"><a href="#1-明确数据集中的变量" class="headerlink" title="1. 明确数据集中的变量"></a>1. 明确数据集中的变量</h1><p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025557.png" alt="image-20240925152446397"></p>
<h1 id="2-具体实现"><a href="#2-具体实现" class="headerlink" title="2. 具体实现"></a>2. 具体实现</h1><h2 id="导包"><a href="#导包" class="headerlink" title="导包"></a>导包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)  <span class="comment"># 忽略警告信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理清洗包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rnd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化包</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># %matplotlib.inline</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 机器学习算法相关包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression,Perceptron,SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC,LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br></pre></td></tr></table></figure>



<p><code>%matplotlib.inline</code>   <strong>魔法函数 magic functions</strong>，模拟命令行，在Ipython编译器里直接使用，内嵌绘图，可忽略plt.show()</p>
<p>官方给出的定义是：IPython有一组预先定义好的所谓的魔法函数（Magic Functions），你可以通过命令行的语法形式来访问它们。可见“%matplotlib inline”就是模仿命令行来访问magic函数的在IPython中独有的形式。</p>
<blockquote>
<p>P.S. pycharm不支持</p>
</blockquote>
<p>magic函数分为两种：</p>
<ul>
<li>面向行，前缀 <code>%</code> ，类似命令行形式</li>
<li>面向单元 ，前缀 <code>%%</code> ，包括当前行以及以下行</li>
</ul>
<p>在这里出现一个报错，</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025204.png" alt="image-20240925160219082"></p>
<p>检查一下是否安装了这个包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip show matplotlib</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025970.png" alt="image-20240925191617490"></p>
<p>是安装了的</p>
<p>问了一下gpt，尝试修改为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<p>发现这就行了</p>
<blockquote>
<p>注意： <code>%</code> 后面无空格，这一行不能有注释</p>
</blockquote>
<h2 id="载入数据集"><a href="#载入数据集" class="headerlink" title="载入数据集"></a>载入数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_df = pd.read_csv(<span class="string">&#x27;./train.csv&#x27;</span>)</span><br><span class="line">test_df = pd.read_csv(<span class="string">&#x27;./test.csv&#x27;</span>)</span><br><span class="line">combine = [train_df, test_df]	<span class="comment"># 合并数据集</span></span><br></pre></td></tr></table></figure>

<p>合并数据集 —&gt; 后面可以直接用 <strong>for循环</strong> 同时对训练集和测试集进行处理 </p>
<h2 id="描述性统计分析"><a href="#描述性统计分析" class="headerlink" title="描述性统计分析"></a>描述性统计分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_df.columns.values)</span><br></pre></td></tr></table></figure>

<p>获得所有特征名（列名）</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025971.png" alt="image-20240925193316241"></p>
<p>预览数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_df.head()		<span class="comment"># 前五行</span></span><br><span class="line">train_df.tail()		<span class="comment"># 后五行</span></span><br></pre></td></tr></table></figure>

<p>前五行数据如下：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025972.png" alt="image-20240925193713811"></p>
<p>后五行数据如下：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025973.png" alt="image-20240925193821162"></p>
<p><strong>判断哪些特征包含缺失值（空值、NULL、NAN）</strong></p>
<p>&#x3D;&#x3D;isnull()函数 和 sum()函数&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_df.isnull().<span class="built_in">sum</span>())		<span class="comment"># 检查每一列中的缺失值数目并返回缺失值数目总和</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;_&#x27;</span>*<span class="number">40</span>)		<span class="comment"># 分隔训练集和测试集的统计结果</span></span><br><span class="line">test_df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025974.png" alt="image-20240925195422532"></p>
<ul>
<li>在训练集中，缺失值数目 <code>Cabin &gt; Age &gt; Embarked</code></li>
<li>在测试集中，缺失值数目 <code>Cabin &gt; Age &gt; Fare</code></li>
</ul>
<p>综上可知，cabin的缺失值很多，而且是字符型和数值型的混合数据，难以处理，后续选择特征时可能丢弃</p>
<p><strong>预览特征的数据类型</strong></p>
<p>&#x3D;&#x3D;info()函数&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_df.info()		<span class="comment"># 预览每个变量的基本信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;_&#x27;</span>*<span class="number">40</span>)</span><br><span class="line">test_df.info()</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025975.png" alt="image-20240925195830416"></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">整数集或浮点型</th>
<th align="center">字符串型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">训练集</td>
<td align="center">7个</td>
<td align="center">5个</td>
</tr>
<tr>
<td align="center">测试集</td>
<td align="center">6个</td>
<td align="center">5个</td>
</tr>
</tbody></table>
<p><strong>样本中数据特征的分布</strong></p>
<p>&#x3D;&#x3D;discribe()函数&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">round</span>(train_df.describe(percentiles=[<span class="number">.5</span>,<span class="number">.6</span>,<span class="number">.7</span>,<span class="number">.75</span>,<span class="number">.8</span>,<span class="number">.9</span>,<span class="number">.99</span>]),<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>percentiles=[.5, .6, .7, .75, .8, .9, .99]</code> 是在调用 <code>describe()</code> 方法时指定的分位数，表示查看的数据分布的不同百分位数，包括中位数（50%）、60%、70%、75%、80%、90% 和99%。</p>
</li>
<li><p><code>round(需要四舍五入的数字或表达式,指定小数点后保留的位数)</code></p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025976.png" alt="image-20240925201252123"></p>
<p>分析得到的表格可以得出：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025977.png" alt="image-20240925201343106"></p>
<p>就是得出每一个特征的分布情况</p>
<p><strong>查看分类特征的数据分布</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df.describe(include=[<span class="string">&#x27;O&#x27;</span>])	<span class="comment"># 其中O是object（字符串型）的缩写</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>用于获取 <code>train_df</code> 中所有对象类型（通常是字符串类型）列的描述性统计信息。</p>
</li>
<li><p>它会返回每一列的计数、唯一值的数量、最常见的值（top）以及该值的频率（freq）。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025978.png" alt="image-20240925201912836"></p>
<p>分析得到信息：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025979.png" alt="image-20240925202055802"></p>
<h2 id="基于数据分析的假设"><a href="#基于数据分析的假设" class="headerlink" title="基于数据分析的假设"></a>基于数据分析的假设</h2><p>分析每个特征与是否幸存的相关性</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025980.png" alt="image-20240925202459636"></p>
<p><strong>先分类汇总，再可视化分析</strong></p>
<p>分类汇总</p>
<p>&#x3D;&#x3D;groupby()函数&#x3D;&#x3D;</p>
<p>相当于Excel中的透视表分析</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;Pclass&#x27;</span>], as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;Survived&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>train_df[[&#39;Pclass&#39;,&#39;Survived&#39;]]</code> ：选择了这两列</li>
<li><code>groupby([&#39;Pclass&#39;], as_index=False)</code> ：按 <code>Pclass</code> 列进行分组，并保持 <code>Pclass</code> 为普通列（而不是索引）</li>
<li><code>mean()</code> ：计算每个舱位的生存率的均值</li>
<li><code>sort_values(by=&#39;Survived&#39;,ascending=False)</code> ：按生存率降序排列</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025981.png" alt="image-20240925204701703"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;Sex&#x27;</span>], as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;Survived&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025982.png" alt="image-20240925204831119"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;SibSp&#x27;</span>], as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;Survived&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025983.png" alt="image-20240925204947448"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[<span class="string">&#x27;Parch&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;Parch&#x27;</span>], as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;Survived&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025984.png" alt="image-20240925205103176"></p>
<p>分析：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025985.png" alt="image-20240925205353738"></p>
<p>注意：<code>SibSp</code> 和 <code>Parch</code> 中有的值与是否幸存是零相关性，所以我们最好的做法是将这两个特征结合成一个新的特征，使新的特征与是否幸存有显著性的相关性</p>
<h2 id="可视化数据分析"><a href="#可视化数据分析" class="headerlink" title="可视化数据分析"></a>可视化数据分析</h2><blockquote>
<p>分析Age与是否幸存相关性</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g = sns.FacetGrid(train_df,col=<span class="string">&#x27;Survived&#x27;</span>)</span><br><span class="line">g.<span class="built_in">map</span>(plt.hist,<span class="string">&#x27;Age&#x27;</span>,bins=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>sns.FacetGrid(train_df, col=&#39;Survived&#39;)</code>：根据 <code>Survived</code> 列的值，创建多个子图</li>
<li><code>g.map(plt.hist, &#39;Age&#39;, bins=20)</code>：在每个子图中绘制 <code>Age</code> 的直方图，并将直方图的箱数设置为 20</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025986.png" alt="image-20240925205916639"></p>
<p>分析：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025987.png" alt="image-20240925205828277"></p>
<blockquote>
<p>分析Pclass与是否幸存相关性</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grid = sns.FacetGrid(train_df,col=<span class="string">&#x27;Pclass&#x27;</span>,hue=<span class="string">&#x27;Survived&#x27;</span>)</span><br><span class="line">grid.<span class="built_in">map</span>(plt.hist,<span class="string">&#x27;Age&#x27;</span>,alpha=<span class="number">0.5</span>,bins=<span class="number">20</span>)</span><br><span class="line">grid.add_legend();</span><br></pre></td></tr></table></figure>

<ul>
<li><code>grid = sns.FacetGrid(train_df, col=&#39;Pclass&#39;, hue=&#39;Survived&#39;)</code> 根据 <code>Pclass</code> 列的值创建多个子图，同时根据 <code>Survived</code> 列的值为数据点上色</li>
<li><code>grid.map(plt.hist, &#39;Age&#39;, alpha=0.5, bins=20)</code> 在每个子图中绘制 <code>Age</code> 的直方图，<code>alpha=0.5</code> 设置了透明度，使得重叠部分可以更清晰地显示。<code>bins=20</code> 表示直方图的箱数为 20</li>
<li><code>grid.add_legend();</code> 添加图例，便于区分不同的生存状态</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025988.png" alt="image-20240925210915984"></p>
<p>分析年龄、票价等级、是否幸存三者的关系：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025989.png" alt="image-20240925211221241"></p>
<blockquote>
<p>分析Embarked与是否幸存相关性</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grid = sns.FacetGrid(train_df,col=<span class="string">&#x27;Embarked&#x27;</span>)</span><br><span class="line">grid.<span class="built_in">map</span>(sns.pointplot,<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>,palette=<span class="string">&#x27;deep&#x27;</span>)</span><br><span class="line">grid.add_legend();</span><br></pre></td></tr></table></figure>

<ul>
<li><code>grid.map(sns.pointplot, &#39;Pclass&#39;, &#39;Survived&#39;, &#39;Sex&#39;, palette=&#39;deep&#39;)</code> 在每个子图中绘制点图，<code>x</code> 轴是 <code>Pclass</code>，<code>y</code> 轴是 <code>Survived</code>，点的颜色根据 <code>Sex</code> 列分组。<code>palette=&#39;deep&#39;</code> 设置颜色调色板</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025990.png" alt="image-20240925211731782"></p>
<p>分析不同的登船港口下，舱位与幸存率的关系，并且按性别进行区分：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025991.png" alt="image-20240925211804997"></p>
<blockquote>
<p>分析Fare与是否幸存相关性</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grid = sns.FacetGrid(train_df,col=<span class="string">&#x27;Embarked&#x27;</span>,hue=<span class="string">&#x27;Survived&#x27;</span>,palette=&#123;<span class="number">0</span>:<span class="string">&#x27;b&#x27;</span>,<span class="number">1</span>:<span class="string">&#x27;r&#x27;</span>&#125;)</span><br><span class="line">grid.<span class="built_in">map</span>(sns.barplot,<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Fare&#x27;</span>,alpha=<span class="number">.5</span>,ci=<span class="literal">None</span>)</span><br><span class="line">grid.add_legend()</span><br></pre></td></tr></table></figure>

<ul>
<li><code>palette=&#123;0:&#39;b&#39;,1:&#39;r&#39;&#125;</code> 指定生存状态的颜色（0 为蓝色，1 为红色）</li>
<li><code>grid.map(sns.barplot, &#39;Sex&#39;, &#39;Fare&#39;, alpha=.5, ci=None)</code> 绘制条形图，<code>x</code> 轴是 <code>Sex</code>，<code>y</code> 轴是 <code>Fare</code>。<code>alpha=.5</code> 设置透明度，<code>ci=None</code> 关闭置信区间的绘制</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025992.png" alt="image-20240925212652875"></p>
<p>分析：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025993.png" alt="image-20240925212302590"></p>
<h2 id="整理、清洗数据"><a href="#整理、清洗数据" class="headerlink" title="整理、清洗数据"></a>整理、清洗数据</h2><p><strong>删除无用特征 Ticket 和 Cabin</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Before&quot;</span>,train_df.shape,test_df.shape,combine[<span class="number">0</span>].shape,combine[<span class="number">1</span>].shape)</span><br><span class="line"></span><br><span class="line">train_df = train_df.drop([<span class="string">&#x27;Ticket&#x27;</span>,<span class="string">&#x27;Cabin&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_df = test_df.drop([<span class="string">&#x27;Ticket&#x27;</span>,<span class="string">&#x27;Cabin&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">combine = [train_df,test_df]</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;After&quot;</span>,train_df.shape,test_df.shape,combine[<span class="number">0</span>].shape,combine[<span class="number">1</span>].shape</span><br></pre></td></tr></table></figure>

<ul>
<li><code>xxx.shape</code> 显示xxx数据集的形状（行数，列数）</li>
<li><code>xxx.drop</code> 删除列</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025994.png" alt="image-20240925214012562"></p>
<p><strong>从现有特征中提取新特征</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[<span class="string">&#x27;Name&#x27;</span>].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025995.png" alt="image-20240926153351587"></p>
<p>从以上的结果我们可以分析出 <code>Name</code> 特征中其实是含有一部分 <code>Title</code> 特征的，那么我们是否可以提取 <code>Title</code> 特征来判断其与是否幸存的相关性呢。</p>
<p>在这里我们可以使用 <strong>正则表达式</strong> 来提取 <code>Title</code> 特征，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;Title&#x27;</span>] = dataset.Name.<span class="built_in">str</span>.extract(<span class="string">&#x27;([A-Za-z]+)\.&#x27;</span>,expand=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">pd.crosstab(train_df[<span class="string">&#x27;Title&#x27;</span>],train_df[<span class="string">&#x27;Sex&#x27;</span>]).sort_values(by=<span class="string">&quot;female&quot;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>for dataset in combine: dataset[&#39;Title&#39;] = dataset.Name.str.extract(&#39;([A-Za-z]+)\.&#39;, expand=False)</code> 对 <code>combine</code> 列表中的每个数据框进行操作，从 <code>Name</code> 列中提取以点号（<code>.</code>）为结束的称谓，并将其存储在新列 <code>Title</code> 中</li>
<li><code>pd.crosstab(train_df[&#39;Title&#39;], train_df[&#39;Sex&#39;]).sort_values(by=&quot;female&quot;, ascending=False)</code> 生成一个交叉表，显示不同称谓和性别（<code>Sex</code>）的计数，并按女性（<code>female</code>）的计数降序排序</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025996.png" alt="image-20240926154727914"></p>
<p>分析 <code>Title</code> 、<code>Age</code> 和是否幸存三者之间的关系</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grid = sns.FacetGrid(train_df,col=<span class="string">&#x27;Title&#x27;</span>,hue=<span class="string">&#x27;Survived&#x27;</span>,col_wrap=<span class="number">3</span>,size=<span class="number">2.5</span>,aspect=<span class="number">1.6</span>)</span><br><span class="line">grid.<span class="built_in">map</span>(plt.hist,<span class="string">&#x27;Age&#x27;</span>,alpha=<span class="number">0.5</span>,bins=<span class="number">20</span>)</span><br><span class="line">grid.add_legend()</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>col=&#39;Title&#39;</code>：按称谓分列</p>
<p><code>hue=&#39;Survived&#39;</code>：根据生存状态上色</p>
<p><code>col_wrap=3</code>：每行最多显示 3 列</p>
<p><code>height=2.5</code> 和 <code>aspect=1.6</code>：设置每个子图的高度和宽高比。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025997.png" alt="image-20240926160044855"></p>
<p>发现有些 <code>Title</code> 很少，我们可以合并这些稀有的 <code>Title</code> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;Title&#x27;</span>] = dataset[<span class="string">&#x27;Title&#x27;</span>].replace([<span class="string">&#x27;Lady&#x27;</span>,<span class="string">&#x27;Countess&#x27;</span>,<span class="string">&#x27;Capt&#x27;</span>,<span class="string">&#x27;Col&#x27;</span>,<span class="string">&#x27;Don&#x27;</span>,<span class="string">&#x27;Dr&#x27;</span>,<span class="string">&#x27;Major&#x27;</span>,<span class="string">&#x27;Rev&#x27;</span>,<span class="string">&#x27;Sir&#x27;</span>,<span class="string">&#x27;Jonkheer&#x27;</span>,<span class="string">&#x27;Dona&#x27;</span>],<span class="string">&#x27;Rare&#x27;</span>)</span><br><span class="line">    dataset[<span class="string">&#x27;Title&#x27;</span>] = dataset[<span class="string">&#x27;Title&#x27;</span>].replace([<span class="string">&#x27;Mlle&#x27;</span>,<span class="string">&#x27;Ms&#x27;</span>],<span class="string">&#x27;Miss&#x27;</span>)</span><br><span class="line">    dataset[<span class="string">&#x27;Title&#x27;</span>] = dataset[<span class="string">&#x27;Title&#x27;</span>].replace([<span class="string">&#x27;Mme&#x27;</span>,<span class="string">&#x27;Mrs&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">train_df[[<span class="string">&#x27;Title&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;Title&#x27;</span>],as_index=<span class="literal">False</span>).mean() </span><br></pre></td></tr></table></figure>

<ul>
<li><code>train_df[[&#39;Title&#39;,&#39;Survived&#39;]].groupby([&#39;Title&#39;],as_index=False).mean() </code> 按 <code>Title</code> 分组，并计算每个称谓的平均生存率</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025998.png" alt="image-20240926161705224"></p>
<p><strong>把分类标题转化为系数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">title_mapping = &#123;<span class="string">&quot;Mr&quot;</span>:<span class="number">1</span>,<span class="string">&quot;Miss&quot;</span>:<span class="number">2</span>,<span class="string">&quot;Mrs&quot;</span>:<span class="number">3</span>,<span class="string">&quot;Master&quot;</span>:<span class="number">4</span>,<span class="string">&quot;Rare&quot;</span>:<span class="number">5</span>&#125;</span><br><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;Title&#x27;</span>] = dataset[<span class="string">&#x27;Title&#x27;</span>].<span class="built_in">map</span>(title_mapping)</span><br><span class="line">    dataset[<span class="string">&#x27;Title&#x27;</span>] = dataset[<span class="string">&#x27;Title&#x27;</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>

<ul>
<li><code>title_mapping = &#123;&quot;Mr&quot;: 1, &quot;Miss&quot;: 2, &quot;Mrs&quot;: 3, &quot;Master&quot;: 4, &quot;Rare&quot;: 5&#125;</code>：创建了一个字典，将每个称谓映射到一个数值</li>
<li><code>dataset[&#39;Title&#39;].map(title_mapping)</code>：将 <code>Title</code> 列中的称谓替换为对应的数值</li>
<li><code>dataset[&#39;Title&#39;].fillna(0)</code>：将缺失值填充为 0</li>
</ul>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025999.png" alt="image-20240926165429128"></p>
<p><strong>从训练集和测试集中删除Name特征以及训练集中的PassengerId特征</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_df = train_df.drop([<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;PassengerId&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_df = test_df.drop([<span class="string">&#x27;Name&#x27;</span>],axis=<span class="number">1</span>)	<span class="comment"># 删除列</span></span><br><span class="line">combine = [train_df,test_df]</span><br><span class="line">train_df.shape,test_df.shape</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025000.png" alt="image-20240926170328977"></p>
<p><strong>转换性别特征Sex</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">        dataset[<span class="string">&#x27;Sex&#x27;</span>] = dataset[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>( &#123;<span class="string">&#x27;female&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;male&#x27;</span>:<span class="number">0</span>&#125; ).astype(<span class="built_in">int</span>)</span><br><span class="line">        </span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025001.png" alt="image-20240926171156359"></p>
<p><strong>填补 Age 的缺失值</strong></p>
<p>填补缺失值的常见做法：运用中位数或均值直接填补</p>
<p><strong>绘制Age、Pclass和Sex的复合直方图</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grid = sns.FacetGrid(train_df,col=<span class="string">&#x27;Pclass&#x27;</span>,hue=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">grid.<span class="built_in">map</span>(plt.hist,<span class="string">&#x27;Age&#x27;</span>,alpha=<span class="number">0.5</span>,bins=<span class="number">20</span>)</span><br><span class="line">grid.add_legend()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025002.png" alt="image-20240926174134905"></p>
<p>注意到 <code>Age</code>、 <code>Sex</code>、 <code>Pclass</code> 之间有关系</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025003.png" alt="image-20240926171449868"></p>
<p>法一：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建两行三列空数组</span></span><br><span class="line">guess_ages = np.zeros((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">guess_ages</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历Sex(0/1)和Pclass(1/2/3)来计算六种组合的Age猜测值</span></span><br><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    <span class="comment"># 第一个for循环计算每一个分组的Age预测值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">3</span>):</span><br><span class="line">            <span class="comment"># guess_df 时每一个分组下非缺失值的 Age 序列</span></span><br><span class="line">            guess_df = dataset[(dataset[<span class="string">&#x27;Sex&#x27;</span>] == i)&amp;(dataset[<span class="string">&#x27;Pclass&#x27;</span>] == j+<span class="number">1</span>)][<span class="string">&#x27;Age&#x27;</span>].dropna()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># age_mean = guess_df.mean()</span></span><br><span class="line">            <span class="comment"># age_std = guess_df.std()</span></span><br><span class="line">            <span class="comment"># age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)</span></span><br><span class="line">            </span><br><span class="line">            age_guess = guess_df.median()  <span class="comment"># 求每个序列的中位数</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#将随机年龄浮点数转换为最接近的 0.5 年龄（四舍五入）</span></span><br><span class="line">            guess_ages[i,j] = <span class="built_in">int</span>(age_guess/<span class="number">0.5</span> + <span class="number">0.5</span>) * <span class="number">0.5</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 第二个for循环对空值进行赋值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">2</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">3</span>):</span><br><span class="line">            dataset.loc[(dataset.Age.isnull())&amp;(dataset.Sex == i)&amp;(dataset.Pclass == j+<span class="number">1</span>),<span class="string">&#x27;Age&#x27;</span>] = guess_ages[i,j]</span><br><span class="line">    </span><br><span class="line">    dataset[<span class="string">&#x27;Age&#x27;</span>] = dataset[<span class="string">&#x27;Age&#x27;</span>].astype(<span class="built_in">int</span>)  <span class="comment"># 将浮点型预测值转化为整形，便于观察</span></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025004.png" alt="image-20240926180049716"></p>
<p>对其进行分组（分箱操作） —&gt; &#x3D;&#x3D;降低模型过拟合的风险&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建年龄段，并确定其与是否幸存的相关性</span></span><br><span class="line"><span class="comment"># 一般在建立分类模型时，需要对连续变量离散化，特征离散化后，模型会更稳定，降低了模型过拟合的风险</span></span><br><span class="line">train_df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(train_df[<span class="string">&#x27;Age&#x27;</span>],<span class="number">5</span>)  <span class="comment"># 将年龄分割为5段，等距分组</span></span><br><span class="line">train_df[[<span class="string">&#x27;AgeBand&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;AgeBand&#x27;</span>],as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;AgeBand&#x27;</span>,ascending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>pandas 中的 <code>cut()</code>函数 —&gt; &#x3D;&#x3D;等距分箱&#x3D;&#x3D;（在本例中将0-80的年龄等距分成五段，再与是否幸存进行分类汇总）</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025005.png" alt="image-20240926234305774"></p>
<p><strong>将年龄段序数化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将这些年龄区间替换为序数</span></span><br><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset.loc[dataset[<span class="string">&#x27;Age&#x27;</span>] &lt;= <span class="number">16</span>,<span class="string">&#x27;Age&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    dataset.loc[(dataset[<span class="string">&#x27;Age&#x27;</span>] &gt; <span class="number">16</span>)&amp;(dataset[<span class="string">&#x27;Age&#x27;</span>] &lt;= <span class="number">32</span>), <span class="string">&#x27;Age&#x27;</span>] = <span class="number">1</span></span><br><span class="line">    dataset.loc[(dataset[<span class="string">&#x27;Age&#x27;</span>] &gt; <span class="number">32</span>)&amp;(dataset[<span class="string">&#x27;Age&#x27;</span>] &lt;= <span class="number">48</span>), <span class="string">&#x27;Age&#x27;</span>] = <span class="number">2</span></span><br><span class="line">    dataset.loc[(dataset[<span class="string">&#x27;Age&#x27;</span>] &gt; <span class="number">48</span>)&amp;(dataset[<span class="string">&#x27;Age&#x27;</span>] &lt;= <span class="number">64</span>), <span class="string">&#x27;Age&#x27;</span>] = <span class="number">3</span></span><br><span class="line">    dataset.loc[dataset[<span class="string">&#x27;Age&#x27;</span>] &gt; <span class="number">64</span>,<span class="string">&#x27;Age&#x27;</span>] = <span class="number">4</span></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025006.png" alt="image-20240926235549204"></p>
<p><strong>删除训练集中生成的 AgeBand 特征</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_df = train_df.drop([<span class="string">&#x27;AgeBand&#x27;</span>],axis=<span class="number">1</span>)  <span class="comment"># 删除训练集中的AgeBand特征</span></span><br><span class="line">combine = [train_df,test_df]</span><br><span class="line">train_df.head()</span><br><span class="line">test_df</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025007.png" alt="image-20240927000010400"></p>
<p><strong>结合 SibSp 和 Parch 特征创建一个新特征 FamilySize （包括兄弟姐妹、配偶、父母、孩子和自己所有家人的数量）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;FamilySize&#x27;</span>] = dataset[<span class="string">&#x27;SibSp&#x27;</span>] + dataset[<span class="string">&#x27;Parch&#x27;</span>] + <span class="number">1</span>		<span class="comment"># 加上的1是自己</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 计算平均生存率</span></span><br><span class="line">train_df[[<span class="string">&#x27;FamilySize&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;FamilySize&#x27;</span>],as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;Survived&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025008.png" alt="image-20240928154046573"></p>
<p>分析以上数据，可以观察到</p>
<ul>
<li><code>FamilySize</code> 和 是否幸存之间有一定的相关性</li>
<li><code>8  11</code> 这行数据与是否幸存是零相关性的 —&gt; &#x3D;&#x3D;创建一个新特征 <code>IsAlone</code>&#x3D;&#x3D;</li>
</ul>
<p><strong>IsAlone 取值为0：不是独自一人，取值为1：独自一人</strong></p>
<p>再次进行分类汇总</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;IsAlone&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    dataset.loc[dataset[<span class="string">&#x27;FamilySize&#x27;</span>] == <span class="number">1</span>,<span class="string">&#x27;IsAlone&#x27;</span>] =<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">train_df[[<span class="string">&#x27;IsAlone&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;IsAlone&#x27;</span>],as_index=<span class="literal">False</span>).mean()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025009.png" alt="image-20240928155227415"></p>
<p>分析数据可知，不是独自一人幸存率高，独自一人幸存率低</p>
<p>这样新特征与是否幸存相关率高了，这样我们就可以删除 <code>Parch</code> <code>SibSp</code> <code>FamilySize</code> 这三个特征了，转化成了 <code>IsAlone</code> 这一个相关性高的特征</p>
<p><strong>删除 SibSp Parch FamilySize 这三个特征</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_df = train_df.drop([<span class="string">&#x27;Parch&#x27;</span>,<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;FamilySize&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">test_df = test_df.drop([<span class="string">&#x27;Parch&#x27;</span>,<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;FamilySize&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">combine = [train_df,test_df]</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025010.png" alt="image-20240928160144881"></p>
<p><strong>创建人工特征 Age 和 Pclass 的交互项，Age*Pclass ，结合 Age 和 Pclass 变量</strong></p>
<p><strong>构建交互项</strong>常见于计量分析，在回归模型中可以更好更有效的分析这个解释变量与被解释变量之间影响的一个作用机制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;Age*Pclass&#x27;</span>] = dataset.Age * dataset.Pclass</span><br><span class="line">    </span><br><span class="line">train_df.loc[:,[<span class="string">&#x27;Age*Pclass&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Pclass&#x27;</span>]].head(<span class="number">10</span>)</span><br><span class="line">train_df[[<span class="string">&#x27;Age*Pclass&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;Age*Pclass&#x27;</span>],as_index=<span class="literal">False</span>).mean()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025011.png" alt="image-20240928160815707"></p>
<p>**填补分类特征 Embarked **</p>
<p>只在训练集中有两个缺失值 ，用 <strong>众数</strong> 填补</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">freq_port = train_df.Embarked.dropna().mode()[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;Embarked&#x27;</span>] = dataset[<span class="string">&#x27;Embarked&#x27;</span>].fillna(freq_port)</span><br><span class="line">    </span><br><span class="line">train_df[[<span class="string">&#x27;Embarked&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;Embarked&#x27;</span>],as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;Survived&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025012.png" alt="image-20240928161551328"></p>
<p><strong>将其序数化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset[<span class="string">&#x27;Embarked&#x27;</span>] = dataset[<span class="string">&#x27;Embarked&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;S&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;C&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;Q&#x27;</span>:<span class="number">2</span>&#125;).astype(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025013.png" alt="image-20240928161825903"></p>
<p><strong>对 Fare 特征进行分箱并替换为序数</strong></p>
<p>在测试集中有一个缺失值，用测试集中 Fare的 <strong>中位数</strong> 填补</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_df[<span class="string">&#x27;Fare&#x27;</span>].fillna(test_df[<span class="string">&#x27;Fare&#x27;</span>].dropna().median(),inplace=<span class="literal">True</span>)</span><br><span class="line">test_df.head()</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025014.png" alt="image-20240928162221698"></p>
<p><code>Fare</code> 是一个连续变量，所以需要以一个分箱操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(train_df[<span class="string">&#x27;Fare&#x27;</span>])</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025015.png" alt="image-20240928162506661"></p>
<p>分析可知，<code>Fare</code> 呈现一个 <strong>右偏分布</strong>，主要分布在0-100之间 —&gt; &#x3D;&#x3D;采用等频分箱&#x3D;&#x3D; —&gt; &#x3D;&#x3D;pandas中的 <code>qcut()</code>函数实现&#x3D;&#x3D;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_df[<span class="string">&#x27;FareBand&#x27;</span>] = pd.qcut(train_df[<span class="string">&#x27;Fare&#x27;</span>],<span class="number">4</span>)</span><br><span class="line">train_df[[<span class="string">&#x27;FareBand&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>]].groupby([<span class="string">&#x27;FareBand&#x27;</span>],as_index=<span class="literal">False</span>).mean().sort_values(by=<span class="string">&#x27;FareBand&#x27;</span>,ascending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>根据相同的样本分位数分为4份</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025016.png" alt="image-20240928163227925"></p>
<p>分析可知，票价越高，幸存率越高</p>
<p><strong>每个分段区间序数化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</span><br><span class="line">    dataset.loc[dataset[<span class="string">&#x27;Fare&#x27;</span>] &lt;= <span class="number">7.91</span>,<span class="string">&#x27;Fare&#x27;</span>] = <span class="number">0</span></span><br><span class="line">    dataset.loc[(dataset[<span class="string">&#x27;Fare&#x27;</span>] &gt; <span class="number">7.91</span>)&amp;(dataset[<span class="string">&#x27;Fare&#x27;</span>] &lt;= <span class="number">14.454</span>),<span class="string">&#x27;Fare&#x27;</span>] = <span class="number">1</span></span><br><span class="line">    dataset.loc[(dataset[<span class="string">&#x27;Fare&#x27;</span>] &gt; <span class="number">14.454</span>)&amp;(dataset[<span class="string">&#x27;Fare&#x27;</span>] &lt;= <span class="number">31</span>),<span class="string">&#x27;Fare&#x27;</span>] = <span class="number">2</span></span><br><span class="line">    dataset.loc[dataset[<span class="string">&#x27;Fare&#x27;</span>] &gt; <span class="number">31</span>,<span class="string">&#x27;Fare&#x27;</span>] = <span class="number">3</span></span><br><span class="line">    dataset[<span class="string">&#x27;Fare&#x27;</span>] = dataset[<span class="string">&#x27;Fare&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">train_df = train_df.drop([<span class="string">&#x27;FareBand&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">combine = [train_df,test_df]</span><br><span class="line"></span><br><span class="line">train_df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025017.png" alt="image-20240928164059837"></p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025018.png" alt="image-20240928164207142"></p>
<p>综上所述，总共得到了八个与是否幸存相关的特征</p>
<h2 id="模型构建与预测"><a href="#模型构建与预测" class="headerlink" title="模型构建与预测"></a>模型构建与预测</h2><p>&#x3D;&#x3D;分类和回归问题&#x3D;&#x3D;</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025019.png" alt="image-20240928172717989"></p>
<p>首先划分训练集特征、对应的类标签、测试集特征</p>
<p>然后用以上的模型去训练，并进行一个模型预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train = train_df.drop(<span class="string">&quot;Survived&quot;</span>,axis=<span class="number">1</span>)</span><br><span class="line">Y_train = train_df[<span class="string">&quot;Survived&quot;</span>]</span><br><span class="line">X_test = test_df.drop(<span class="string">&quot;PassengerId&quot;</span>,axis=<span class="number">1</span>).copy()</span><br><span class="line">X_train.shape,Y_train.shape,X_test.shape</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025020.png" alt="image-20240928173313379"></p>
<h3 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a><strong>逻辑回归模型</strong></h3><p>通过 <code>sigmoid()</code>函数（逻辑回归函数）将逻辑回归问题转换为一个简单的<strong>线性回归</strong>问题，就可以用来测量分类因变量和一个或多个自变量之间的关系。 常见的就是用来处理二分类问题，<strong>我们需要关注的是模型基于训练集模型生成的置信度分数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 逻辑回归模型</span></span><br><span class="line">logreg = LogisticRegression()</span><br><span class="line">logreg.fit(X_train,Y_train)		<span class="comment"># 用训练集特征和对应的类标签拟合逻辑回归模型</span></span><br><span class="line">y_pred = logreg.predict(X_test)		<span class="comment"># 用测试集的特征进行预测，预测测试集的一个类标签</span></span><br><span class="line">acc_log = <span class="built_in">round</span>(logreg.score(X_train,Y_train) * <span class="number">100</span>, <span class="number">2</span>)		<span class="comment"># 用score函数评价模型的好坏</span></span><br><span class="line">acc_log</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025021.png" alt="image-20241021145142030"></p>
<p>逻辑回归本质上是做一个分类，但也是一个回归模型</p>
<p>可以使用逻辑回归中特征的一个系数，去研究各个特征对于 <code>Survived</code> 的影响程度</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025022.png" alt="image-20241021150740053"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">coeff_df = pd.DataFrame(train_df.columns.delete(<span class="number">0</span>))</span><br><span class="line">coeff_df.columns = [<span class="string">&#x27;Feature&#x27;</span>]</span><br><span class="line">coeff_df[<span class="string">&quot;Correlation&quot;</span>] = pd.Series(logreg.coef_[<span class="number">0</span>])</span><br><span class="line">coeff_df.sort_values(by=<span class="string">&#x27;Correlation&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>通过 <code>logreg.coef</code> 看每一个特征对应的系数</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025023.png" alt="image-20241021150502775"></p>
<p>通过结果，可以发现</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025024.png" alt="image-20241021150727875"></p>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a><strong>支持向量机</strong></h3><p>支持向量机是一类按<strong>监督学习方式</strong>对数据进行<strong>二元分类</strong>的<strong>广义线性分类器</strong>，他的决策边界是对学习样本求解的<strong>最大边距超平面</strong>。</p>
<p>最为常见的是<strong>通过核函数的方法进行非线性分类</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 支持向量机模型</span></span><br><span class="line">svc = SVC()</span><br><span class="line">svc.fit(X_train,Y_train)</span><br><span class="line">y_pred = svc.predict(X_test)</span><br><span class="line">acc_svc = <span class="built_in">round</span>(svc.score(X_train,Y_train) * <span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line">acc_svc</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025025.png" alt="image-20241021152048671"></p>
<p>该模型生成的置信分数<strong>高于</strong>逻辑回归模型。</p>
<h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a><strong>KNN</strong></h3><p>k近邻算法是一种用于分类和回归的非参数方法</p>
<p>基本思想：在特征空间中，如果一个样本附近的k个最近样本的大多数属于某一个类别，则该样本也属于这个类别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KNN</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors = <span class="number">3</span>)</span><br><span class="line">knn.fit(X_train, Y_train)</span><br><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line">acc_knn = <span class="built_in">round</span>(knn.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line">acc_knn</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025026.png" alt="image-20241021152115685"></p>
<p>KNN算法置信分数高于逻辑回归、支持向量机</p>
<h3 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a><strong>朴素贝叶斯分类器</strong></h3><p>是一系列以假设<strong>特征之间强独立</strong>下运用贝叶斯定理为基础的简单概率分类器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 朴素贝叶斯分类器</span></span><br><span class="line">gaussian = GaussianNB()</span><br><span class="line">gaussian.fit(X_train,Y_train)</span><br><span class="line">Y_pred = gaussian.predict(X_test)</span><br><span class="line">acc_gaussian = <span class="built_in">round</span>(gaussian.score(X_train,Y_train)*<span class="number">100</span>,<span class="number">2</span>)</span><br><span class="line">acc_gaussian</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025027.png" alt="image-20241021192113153"></p>
<p>生成的置信分数是目前评估之中最低的</p>
<h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a><strong>感知机</strong></h3><p>感知机是一种用于<strong>监督学习二元分类</strong>的算法（可以决定由数字向量表示的输入是否属于某个特定类的函数）。他是一种<strong>线性分类器</strong>，即基于将一组权重与特征向量相结合的线性预测函数进行预测的分类算法</p>
<p>数据集是线性可分的，那么感知机学习的目标是：求解一个能够将训练集正实例点和负实例点完全正确分开的一个超平面</p>
<p>求解感知机模型 —&gt; 求解线性可分支持向量机的一个过程，再应用硬间隔最大化，就成为了线性可分支持向量机</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 感知机</span></span><br><span class="line">perceptron = Perceptron()</span><br><span class="line">perceptron.fit(X_train, Y_train)</span><br><span class="line">Y_pred = perceptron.predict(X_test)</span><br><span class="line">acc_perceptron = <span class="built_in">round</span>(perceptron.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line">acc_perceptron</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025028.png" alt="image-20241021193603200"></p>
<p>置信得分最低</p>
<p>—&gt; 数据不是线性可分的</p>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a><strong>决策树</strong></h3><p>核心思想：在一个训练集中找到一个最优特征，然后从这个特征的候选值中找到一个最优的候选值，根据这个最优的候选值把数据分为两个子数据集，然后递归上述操作，直到满足条件为止</p>
<p>将<strong>特征（树枝）映射到目标值（树叶）</strong>的分类或回归方法。目标变量可以取一组<strong>有限值</strong>的树模型称为分类树；在这些树结构中，<strong>叶子代表类标签</strong>，<strong>分支代表导致这些类标签的特征的结合</strong>。目标变量可以取连续值的决策树称为回归树。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 决策树</span></span><br><span class="line">decision_tree = DecisionTreeClassifier()</span><br><span class="line">decision_tree.fit(X_train, Y_train)</span><br><span class="line">Y_pred = decision_tree.predict(X_test)</span><br><span class="line">acc_decision_tree = <span class="built_in">round</span>(decision_tree.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line">acc_decision_tree</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025029.png" alt="image-20241021200312673"></p>
<p>评估得分最高，有很好的分类效果</p>
<p><strong>决策树可视化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 决策树可视化</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">import</span> pydotplus</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line">dot_data = tree.export_graphviz(decision_tree, out_file=<span class="literal">None</span>,</span><br><span class="line">                               feature_names=X_train.columns,</span><br><span class="line">                               class_names=[<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>],</span><br><span class="line">                               max_depth=<span class="number">3</span>,</span><br><span class="line">                               filled=<span class="literal">True</span>, rounded=<span class="literal">True</span>,</span><br><span class="line">                               special_characters=<span class="literal">True</span>)</span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data)</span><br><span class="line">Image(graph.create_png())</span><br></pre></td></tr></table></figure>

<ul>
<li><code>dot_data = tree.export_graphviz(...)</code>：用 <code>tree.export_graphviz()</code> 函数将决策树导出为 <code>.dot</code> 格式的数据流<ul>
<li><code>decision_tree</code> ：我们的决策树模型</li>
<li><code>out_file=None</code> ：不输出写到文件中</li>
<li><code>feature_names=X_train.columns</code> ：传入特征的名称列表， <code>X_train</code> 是训练数据集， <code>X_train.columns</code> 是特征的名称</li>
<li><code>class_names=[&#39;0&#39;,&#39;1&#39;]</code> ：分类标签的名称，幸存为没有幸存为0</li>
<li><code>max_depth=3</code> ：决策树的深度，为看清图片，设置为3</li>
<li><code>filled=True</code> ：节点根据分类概率进行颜色填充</li>
<li><code>rounded=True</code> ：节点的形状为圆角矩阵</li>
<li><code>special_characters=True</code> ：启用特殊字符支持</li>
</ul>
</li>
<li><code>graph = pydotplus.graph_from_dot_data(dot_data)</code> ：用 <code>pydotplus</code> 库的 <code>graph_from_dot_data()</code> 函数将 <code>.dot</code> 格式的数据转换为一个可以处理的图结构（<code>graph</code> 对象）。</li>
<li><code>Image(graph.create_png())</code> ：用 <code>graph.create_png()</code> 将图结构转换为 PNG 格式的图像。<code>Image()</code> 函数用于在 Jupyter Notebook 中显示生成的 PNG 图像。</li>
</ul>
<p>这里会出现一个报错</p>
<blockquote>
<p>InvocationException: GraphViz’s executables not found</p>
</blockquote>
<p>不是没有安装这个包，Graphviz不是一个python tool，而是要单独安装 <code>GraphViz</code> </p>
<p><a target="_blank" rel="noopener" href="https://www.graphviz.org/">https://www.graphviz.org/</a></p>
<p>下载后，配置环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dot -version</span><br></pre></td></tr></table></figure>

<p>检验是否安装配置成功</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025030.png" alt="image-20241022091641684"></p>
<ul>
<li>根节点是 <code>Sex</code> 特征</li>
<li><code>gini</code> 是指 <strong>基尼系数</strong> ，基尼系数越小，分类越纯，划分得越好</li>
<li><code>sample</code> 指的是样本数</li>
<li><code>value</code> 指的是类标签对应的样本数</li>
<li>左边为 <code>True</code> ，右边为 <code>False</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dot_data = tree.export_graphviz(decision_tree, out_file=<span class="literal">None</span>,</span><br><span class="line">                               feature_names=X_train.columns,</span><br><span class="line">                               filled=<span class="literal">True</span>, rounded=<span class="literal">True</span>,</span><br><span class="line">                               special_characters=<span class="literal">True</span>)</span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data)</span><br><span class="line">graph.write_pdf(<span class="string">&quot;DTree.pdf&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>导出完整决策树</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025031.png" alt="image-20241022103021568"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[(train_df[<span class="string">&#x27;Sex&#x27;</span>]&lt;=<span class="number">0.5</span>) &amp; (train_df[<span class="string">&#x27;Age*Pclass&#x27;</span>]&gt;<span class="number">1.5</span>) &amp; (train_df[<span class="string">&#x27;Pclass&#x27;</span>]&gt;<span class="number">1.5</span>) &amp; (train_df[<span class="string">&#x27;Age&#x27;</span>]&lt;=<span class="number">1.5</span>) &amp; (train_df[<span class="string">&#x27;Fare&#x27;</span>]&lt;=<span class="number">2.5</span>) &amp; (train_df[<span class="string">&#x27;Title&#x27;</span>]&lt;=<span class="number">2.5</span>) &amp; (train_df[<span class="string">&#x27;Embarked&#x27;</span>]&gt;<span class="number">0.5</span>) &amp; (train_df[<span class="string">&#x27;Embarked&#x27;</span>]&lt;=<span class="number">1.5</span>) &amp; (train_df[<span class="string">&#x27;IsAlone&#x27;</span>]&gt;<span class="number">0.5</span>) &amp; (train_df[<span class="string">&#x27;Fare&#x27;</span>]&gt;<span class="number">0.5</span>) &amp; (train_df[<span class="string">&#x27;Fare&#x27;</span>]&lt;=<span class="number">1.5</span>) &amp; (train_df[<span class="string">&#x27;Age*Pclass&#x27;</span>]&lt;=<span class="number">2.5</span>)]</span><br></pre></td></tr></table></figure>

<p>根据决策树去检索样本，验证决策树对于样本的分类</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025032.png" alt="image-20241022103111223"></p>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a><strong>随机森林</strong></h3><p>基于 <code>bagging</code> 的一种集成学习方法，用于分类、回归和其他任务。</p>
<p>通过<strong>自助重采样技术</strong>，从原始训练样本集中<strong>有放回地</strong>重复随机抽取 n 个样本生成<strong>新的训练样本集合</strong>训练决策树，然后按照以上步骤生成 m 棵决策树组成<strong>随机森林</strong>，新数据的分类结果按<strong>分类树投票多少形成的分数</strong>而定。</p>
<p>实质是对决策树算法地一种改进，将多个决策树合并在一起，每棵树的建立依赖于独立抽取的样本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机森林</span></span><br><span class="line">random_forest = RandomForestClassifier(n_estimators=<span class="number">100</span>)</span><br><span class="line">random_forest.fit(X_train, Y_train)</span><br><span class="line">Y_pred = random_forest.predict(X_test)</span><br><span class="line">random_forest.score(X_train, Y_train)</span><br><span class="line">acc_random_forest = <span class="built_in">round</span>(random_forest.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line">acc_random_forest</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025033.png" alt="image-20241022104457252"></p>
<h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>对所有的模型评估结果进行排名，选择最适合问题的模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">models = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: [<span class="string">&#x27;Support Vector Machine&#x27;</span>, <span class="string">&#x27;KNN&#x27;</span>, <span class="string">&#x27;Logistic Regression&#x27;</span>, </span><br><span class="line">             <span class="string">&#x27;Random Forest&#x27;</span>, <span class="string">&#x27;Naive Bayes&#x27;</span>, <span class="string">&#x27;Perceptron&#x27;</span>,<span class="string">&#x27;Decision&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;Score&#x27;</span>: [acc_svc, acc_knn, acc_log,</span><br><span class="line">             acc_random_forest, acc_gaussian, acc_perceptron, acc_decision_tree]&#125;)</span><br><span class="line">models.sort_values(by=<span class="string">&#x27;Score&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>



<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025034.png" alt="image-20241022105553995"></p>
<p>决策树和随机森林的得分相同，但是我们选择随机森林（决策树的改进版），因为他纠正了决策树过度拟合训练集带来的缺陷</p>
<h2 id="提交预测结果"><a href="#提交预测结果" class="headerlink" title="提交预测结果"></a>提交预测结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">submission = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&quot;PassengerId&quot;</span>: test_df[<span class="string">&quot;PassengerId&quot;</span>],</span><br><span class="line">    <span class="string">&quot;Survived&quot;</span>: Y_pred</span><br><span class="line">&#125;)</span><br><span class="line">submission.to_csv(<span class="string">&#x27;./submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>





<blockquote>
<p>需要关注的问题</p>
</blockquote>
<ul>
<li>为什么要从名字这种文本数据中提取特征？</li>
</ul>
<p><strong>挖掘潜在信息</strong></p>
<p><strong>增加特征维度</strong></p>
<ul>
<li>填补年龄特征时，为什么不直接用均值或者中位数去填补，而用相关特征分为6组分别填补？</li>
</ul>
<p><strong>考虑特征相关性</strong></p>
<p><strong>提高数据准确性</strong></p>
<p><strong>减少模型偏差</strong></p>
<ul>
<li><code>SipSp</code> 和 <code>Parch</code> 特征是数据集中比较好的数据了，为什么还需要把他们合并，构造一个新的特征呢？</li>
</ul>
<p><strong>提升特征相关性</strong></p>
<p><strong>简化模型和避免多重共线性</strong></p>
<ul>
<li>年龄特征分段为什么采用的是等距分箱？而票价特征就采用等频分箱呢？</li>
</ul>
<p>年龄特征采用等距分箱的原因：</p>
<p><strong>自然年龄区间的考虑</strong></p>
<p><strong>数据分布和模型稳定性</strong></p>
<p>票价特征采用等频分箱的原因：</p>
<p><strong>票价数据的偏态分布</strong></p>
<p><strong>突出票价差异对幸存率的影响</strong></p>
<p>总结：</p>
<p><img src="https://raw.githubusercontent.com/betty11618/images/img/202410222025035.png" alt="img"></p>
<p>纯种小白的第一次kaggle竞赛尝试，纯纯跟着视频敲的，最后提交的得分不高，课堂上讲的纯理论也不太跟得上，还是下来以赛促学吧，再了解了解理论，好歹也算是在今天敲到机器学习的门槛了，接下来的日子多多加油吧！！！</p>
<p>2024年10月22日</p>
<p>参考资料：</p>
<p>【【建议收藏】机器学习实战 泰坦尼克号幸存者预测 | Kaggle竞赛实例系列】<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11F411u7Ck?vd_source=77e1fe7a7419fa7dbd62746624c75975">https://www.bilibili.com/video/BV11F411u7Ck?vd_source=77e1fe7a7419fa7dbd62746624c75975</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/liangzuojiayi/article/details/78183783">https://blog.csdn.net/liangzuojiayi/article/details/78183783</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/09/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/" rel="prev" title="机器学习入门">
      <i class="fa fa-chevron-left"></i> 机器学习入门
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%91%E6%88%98"><span class="nav-number">1.</span> <span class="nav-text">挑战</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E6%98%8E%E7%A1%AE%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F"><span class="nav-number"></span> <span class="nav-text">1. 明确数据集中的变量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="nav-number"></span> <span class="nav-text">2. 具体实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E5%8C%85"><span class="nav-number">1.</span> <span class="nav-text">导包</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BD%BD%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">2.</span> <span class="nav-text">载入数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90"><span class="nav-number">3.</span> <span class="nav-text">描述性统计分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%9A%84%E5%81%87%E8%AE%BE"><span class="nav-number">4.</span> <span class="nav-text">基于数据分析的假设</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="nav-number">5.</span> <span class="nav-text">可视化数据分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B4%E7%90%86%E3%80%81%E6%B8%85%E6%B4%97%E6%95%B0%E6%8D%AE"><span class="nav-number">6.</span> <span class="nav-text">整理、清洗数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%A2%84%E6%B5%8B"><span class="nav-number">7.</span> <span class="nav-text">模型构建与预测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">7.1.</span> <span class="nav-text">逻辑回归模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-number">7.2.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN"><span class="nav-number">7.3.</span> <span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">7.4.</span> <span class="nav-text">朴素贝叶斯分类器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">7.5.</span> <span class="nav-text">感知机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">7.6.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-number">7.7.</span> <span class="nav-text">随机森林</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="nav-number">8.</span> <span class="nav-text">模型评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E4%BA%A4%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="nav-number">9.</span> <span class="nav-text">提交预测结果</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
